# Adversarial Reinforcement Learning Papers
This is a collection of adversarial reinforcement learning papers. Each category is a potential start point for you to start your research. Some papers are listed more than once because they belong to multiple categories.

Adversarial reinforcement learning is closely related to robust reinforcement learning and attacks in reinforcement learning. If you are looking for papers in adversarial reinforcement learning, you should also see papers related to robust reinforcement learning and attacks in reinforcement learning.

For MARL resources, please refer to [Multi Agent Reinforcement Learning papers](https://github.com/TimeBreaker/Multi-Agent-Reinforcement-Learning-papers), [MARL Papers with Code](https://github.com/TimeBreaker/MARL-papers-with-code) and [MARL Resources Collection](https://github.com/TimeBreaker/MARL-resources-collection).

I will continually update this repository and I welcome suggestions. (missing important papers, missing categories, invalid links, etc.) This is only a first draft so far and I'll add more resources in the next few months.

This repository is not for commercial purposes.

My email: chenhao915@mails.ucas.ac.cn


## Overview
* [Single-Agent](https://github.com/TimeBreaker/Adversarial-Reinforcement-Learning-Papers#single-agent)
* [Multi-Agent](https://github.com/TimeBreaker/Adversarial-Reinforcement-Learning-Papers#multi-agent)
* [Adversarial Communication](https://github.com/TimeBreaker/Adversarial-Reinforcement-Learning-Papers#adversarial-communication)
* [Benchmark](https://github.com/TimeBreaker/Adversarial-Reinforcement-Learning-Papers#benchmark)


## Single-Agent
Paper|Code|Accepted at|Year
--|:--:|:--:|--:
[Robust Adversarial Reinforcement Learning](http://proceedings.mlr.press/v70/pinto17a/pinto17a.pdf)|Non-official implements on GitHub|ICML|2017
[Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations](https://proceedings.neurips.cc/paper/2020/file/f0eb6568ea114ba6e293f903c34d7488-Paper.pdf)|https://github.com/chenhongge/StateAdvDRL|NIPS|2020
[Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training](https://arxiv.org/pdf/2202.09514)|||2022
[Risk Averse Robust Adversarial Reinforcement Learning](https://arxiv.org/pdf/1904.00511)||ICRA|2019
[Robust Deep Reinforcement Learning with Adversarial Attacks](https://arxiv.org/pdf/1712.03632)|||2017
[Robust Reinforcement Learning on State Observations with Learned Optimal Adversary](https://arxiv.org/pdf/2101.08452)|https://github.com/huanzhang12/ATLA_robust_RL|ICLR|2021
[Exploring the Training Robustness of Distributional Reinforcement Learning against Noisy State Observations](https://arxiv.org/pdf/2109.08776)|||2021
[RoMFAC: A Robust Mean-Field Actor-Critic Reinforcement Learning against Adversarial Perturbations on States](https://arxiv.org/pdf/2205.07229)|||2022
[Adversary Agnostic Robust Deep Reinforcement Learning](https://arxiv.org/pdf/2008.06199)||TNNLS|2021
[Learning to Cope with Adversarial Attacks](https://arxiv.org/pdf/1906.12061)|||2019
[Adversarial Attack on Graph Structured Data](http://proceedings.mlr.press/v80/dai18b/dai18b.pdf)||ICML|2018
[Characterizing Attacks on Deep Reinforcement Learning](http://proceedings.mlr.press/v80/dai18b/dai18b.pdf)||AAMAS|2022
[Adversarial policies: Attacking deep reinforcement learning](https://arxiv.org/pdf/1905.10615)|https://github.com/HumanCompatibleAI/adversarial-policies|ICLR|2020
[Learning Robust Policy against Disturbance in Transition Dynamics via State-Conservative Policy Optimization](https://ojs.aaai.org/index.php/AAAI/article/view/20686/20445)||AAAI|2022
[On the Robustness of Safe Reinforcement Learning under Observational Perturbations](https://arxiv.org/pdf/2205.14691)|||2022
[Robust Reinforcement Learning using Adversarial Populations](https://arxiv.org/pdf/2008.01825)|||2020


## Multi-Agent
Paper|Code|Accepted at|Year
--|:--:|:--:|--:
[Certifiably Robust Policy Learning against Adversarial Communication in Multi-agent Systems](https://arxiv.org/pdf/2206.10158)|||2022
[Distributed Multi-Agent Deep Reinforcement Learning for Robust Coordination against Noise](https://arxiv.org/pdf/2205.09705)|||2022
[On the Robustness of Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2003.03722)||IEEE Security and Privacy Workshops|2020
[Towards Comprehensive Testing on the Robustness of Cooperative Multi-agent Reinforcement Learning](https://openaccess.thecvf.com/content/CVPR2022W/ArtOfRobust/papers/Guo_Towards_Comprehensive_Testing_on_the_Robustness_of_Cooperative_Multi-Agent_Reinforcement_CVPRW_2022_paper.pdf)||CVPR workshop|2022
[Robust Multi-Agent Reinforcement Learning via Minimax Deep Deterministic Policy Gradient](https://ojs.aaai.org/index.php/AAAI/article/view/4327/4205)||AAAI|2019
[Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations](https://arxiv.org/pdf/1812.00922)||NIPS Deep Reinforcement Learning Workshop|2018
[Policy Regularization via Noisy Advantage Values for Cooperative Multi-agent Actor-Critic methods](https://arxiv.org/pdf/2106.14334)|||2021


## Adversarial Communication
Paper|Code|Accepted at|Year
--|:--:|:--:|--:
[Certifiably Robust Policy Learning against Adversarial Communication in Multi-agent Systems](https://arxiv.org/pdf/2206.10158)|||2022


## Benchmark
Paper|Code|Accepted at|Year
--|:--:|:--:|--:
[Towards Comprehensive Testing on the Robustness of Cooperative Multi-agent Reinforcement Learning](https://openaccess.thecvf.com/content/CVPR2022W/ArtOfRobust/papers/Guo_Towards_Comprehensive_Testing_on_the_Robustness_of_Cooperative_Multi-Agent_Reinforcement_CVPRW_2022_paper.pdf)||CVPR workshop|2022


## Citation

If you find this repository useful, please cite our repo:
```
@misc{chen2022adversarial,
  author={Chen, Hao},
  title={Adversarial Reinforcement Learning Papers},
  year={2022}
  publisher = {GitHub},
  journal = {GitHub Repository},
  howpublished = {\url{https://github.com/TimeBreaker/Adversarial-Reinforcement-Learning-Papers}}
}
```
